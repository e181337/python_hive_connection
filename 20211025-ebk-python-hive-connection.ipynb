{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f175951b",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Writing pandas df to hive db </h2>\n",
    "\n",
    "<h2 align=\"center\"> Erinç Koç </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c5b246",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Outline </h2><br>\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "* [1) Import Libraries & Data ](#chapter1)\n",
    "* [2) Kerberos Authentication](#chapter2)\n",
    "* [3) Connect to Cluster Through Kerberos Auth](#chapter3)\n",
    "* [4) Generate Data to Insert DB](#chapter4)\n",
    "* [5) Generate Table in Database](#chapter5)\n",
    "* [6) Insert Data to Table](#chapter6)\n",
    "* [7) Fetch Inserted Data](#chapter7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19a0ea",
   "metadata": {},
   "source": [
    "### 1) Import Libraries & Data<a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhive import hive\n",
    "import time \n",
    "import pandas as pd\n",
    "import os, subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bed995",
   "metadata": {},
   "outputs": [],
   "source": [
    "### display-related options\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 2000)\n",
    "pd.set_option('display.max_seq_items', 2000)\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c6f32",
   "metadata": {},
   "source": [
    "### 2) Kerberos Authentication <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed0a8b",
   "metadata": {},
   "source": [
    "##### Authentication should be generated at OS level. I WON'T add keytab files due to privacy issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99dede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get kerberos ticket\n",
    "stream = os.popen('kinit -kt data.keytab user1@pyd.pym')\n",
    "output = stream.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1937b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###check status of ticket\n",
    "def ticket_check():\n",
    "    return True if subprocess.call(['klist', '-s']) == 0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd8c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ticket_check():\n",
    "    print('Kerberos ticket is valid')\n",
    "else:  \n",
    "    raise RuntimeError('No valid kerberos ticket')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5aca26",
   "metadata": {},
   "source": [
    "### 3) Connect to Cluster Through Kerberos Auth <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = hive.Connection(host=\"hivenode1\",port=10000,username=\"user1\",auth=\"KERBEROS\",kerberos_service_name=\"hive\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f04d88",
   "metadata": {},
   "source": [
    "### 4) Generate Data to Insert DB <a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = []\n",
    "column_length = 100\n",
    "row_length = 100\n",
    "for i in range(column_length):\n",
    "    column_name.append(\"col\" + str(i))\n",
    "df = pd.DataFrame(np.random.randint(0,100,size=(row_length,column_length)), columns=column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b8ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total size of df {:.8f}'.format((df.values.nbytes + df.index.nbytes + df.columns.nbytes ) / 1024.0**3).format() + ' gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d93eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert df to tuples in order to use it in sql query \n",
    "for r in df.columns.values:\n",
    "    df[r] = df[r].map(str)\n",
    "    df[r] = df[r].map(str.strip)   \n",
    "tuples = [tuple(x) for x in df.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c63258",
   "metadata": {},
   "source": [
    "Convert dataframe to chunks of size n so that in each trial n number of data will be inserted to hive table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd95f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "new_list = chunks(tuples, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7893346",
   "metadata": {},
   "source": [
    "##### There exists a better way to write data to a hive table. partiained hiver table can be used. Moreover, by using multi thread or multi process option of python, multi partitions can be inserted the table location. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ad70e",
   "metadata": {},
   "source": [
    "### 4) Generate Table in Database <a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "### match type of pandas df to hive type\n",
    "def type_conversion(df, i):\n",
    "    if df[i].dtypes == np.float64:\n",
    "        column_type = \"FLOAT\"\n",
    "    if df[i].dtypes == np.int64:\n",
    "        column_type = \"FLOAT\"\n",
    "    if df[i].dtypes == object:\n",
    "        column_type = \"STRING\"\n",
    "    else:\n",
    "        raise RuntimeError(\"No type\")\n",
    "    return column_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe9dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Table creation script is generated as string\n",
    "def generate_create_statment(df, db_name, table_name):\n",
    "    column_list = df.columns.values.tolist()\n",
    "    create_statement = \"CREATE TABLE \" + db_name + \".\" + table_name + \" (\"\n",
    "    for i in column_list:\n",
    "        corrent_type = type_conversion(df, i)\n",
    "        create_statement += i + \" \" + corrent_type + \", \"\n",
    "    create_statement = create_statement[:-2]\n",
    "    create_statement = create_statement + \")\"\n",
    "    return create_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837aef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'sasl_db'\n",
    "table_name = 'table_1'\n",
    "statement_1 = f\"DROP TABLE IF EXISTS {db_name}.{table_name}\"\n",
    "statement = generate_create_statment(df, db_name, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(statement_1)\n",
    "cur.execute(statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd878d0",
   "metadata": {},
   "source": [
    "### 6) Insert Data to Table <a class=\"anchor\" id=\"chapter6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate insertion script as string and then insert to table in db\n",
    "start_time = time.time()\n",
    "for i in range(len(new_list)):\n",
    "    sql = f\"INSERT INTO {db_name}.{table_name}\" + \" VALUES {}\".format(new_list[i])\n",
    "    for char in ['[', ']']:\n",
    "        sql = sql.replace(char, \"\")\n",
    "    cur.execute(sql)\n",
    "print(\"---execution time %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bc5e61",
   "metadata": {},
   "source": [
    "### 7) Fetch Inserted Data <a class=\"anchor\" id=\"chapter7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4754bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(f\"select * from {db_name}.{table_name}\")\n",
    "df_insert = pd.DataFrame(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b41b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_data",
   "language": "python",
   "name": "env_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
